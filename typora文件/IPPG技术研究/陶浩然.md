测量参数的程序

svm的分类



+ 视频转图片序列

```python
'''
video2pic：视频转图像序列的函数
'''
EXTRACT_FREQUENCY = 1
def video2pic(videopath, path_3, index=EXTRACT_FREQUENCY):
    dst_folder = videopath.split('.', 1)[0]
    try:
        shutil.rmtree(dst_folder)
    except OSError:
        pass
    os.mkdir(dst_folder)
    video = cv2.VideoCapture()
    if not video.open(videopath):
        print("can not open the video")
        exit(1)
    count = 1
    while True:
        _, frame = video.read()
        if frame is None:
            break
        if count % EXTRACT_FREQUENCY == 0:
            save_path = path_3 + str(index) + ".bmp"  # 图片格式在这里修改
            cv2.imwrite(save_path, frame)
            index += 1
        count += 1
    video.release()
    print(">>>视频转图片序列存储完成>>>")
    print("--------------------------------------Totally save {:d} pics--------------------------------------".format(index - 1))
```

+ 对图像序列面部分区切片

```python
def dir_record_analysis(path2, path1, path3, fps, dataType1 = '.jpg', dataType2 = '.bmp', cal_ptt = False):
    """

    :param path2: 输入图片地址
    :param path1: 结果1地址
    :param path3: 结果2地址
    :param fps: 采样率
    :param dataType1: 输入图像类型
    :param dataType2: 输出图像类型
    :param cal_ptt: 是否计算PTT
    :return:
    """
    '''
    3-1 切片地址保存
    '''
    print("--------------------------------------面部定位、分区、切片、存储开始--------------------------------------")
    slice_path = path1 + "\\slice\\"
    face_path = path1 + "\\face\\"
    if cal_ptt == True:
        lf_path = path1 + "\\lf\\"
        rf_path = path1 + "\\rf\\"
        if not os.path.exists(lf_path):
            os.makedirs(lf_path)
        if not os.path.exists(rf_path):
            os.makedirs(rf_path)
    if not os.path.exists(slice_path):
        os.makedirs(slice_path)
    if not os.path.exists(face_path):
        os.makedirs(face_path)
    pathDir = os.listdir(path2)
    LEN = 0
    first_img = 0
    for i, tmp in enumerate(pathDir):
        # print(i, tmp)
        if dataType1 in tmp:
            LEN += 1
            if LEN == 1:
                first_img = i
    pathDir = pathDir[first_img:first_img + LEN]
    files_list = sorted(pathDir, key=lambda x: int("".join(x.split(".")[0])))   #根据文件名称选择整理内容
    # files_list = sorted(pathDir, key=lambda x: int("".join(x.split(".")[0])))
    filepath = os.path.join(path2, files_list[0])  # 图片的地址
    img = cv2.imread(filepath)
    # img = cv2.resize(img, (0, 0), fx=0.25, fy=0.25, interpolation=cv2.INTER_AREA)
    cv2.imwrite(path1 + "full_face.jpg", img)
    print("保存首帧图像完成。")
    print("面部检测及ROI定位开始。")
    if cal_ptt == True:
        forehead_cen, lf_cen, rf_cen, center_all, tri_list = run(path1 + "full_face.jpg", cal_ptt=cal_ptt)
    else:
        forehead_cen = run(path1 + "full_face.jpg")

    rois = []
    if forehead_cen != 0:
        # ROI区域大小为150px*150px
        x_start, x_end, y_start, y_end = forehead_cen[0]-18, forehead_cen[0]+19, forehead_cen[1]-18, forehead_cen[1]+19
        roi_top = (y_start, y_end, x_start, x_end, 'forehead')  # 额头150*150的方形区域
        rois.append(roi_top)
        if cal_ptt == True:
            lfx_start, lfx_end, lfy_start, lfy_end = lf_cen[0]-18, lf_cen[0]+19, lf_cen[1]-18, lf_cen[1]+19
            rfx_start, rfx_end, rfy_start, rfy_end = rf_cen[0]-18, rf_cen[0]+19, rf_cen[1]-18, rf_cen[1]+19
            roi_left = (lfy_start, lfy_end, lfx_start, lfx_end, 'left cheek')  # 图中左脸150*150的方形区域
            roi_right = (rfy_start, rfy_end, rfx_start, rfx_end, 'right cheek')  # 图中右脸150*150的方形区域
            rois.append(roi_left)
            rois.append(roi_right)
    else:
        # x_start, x_end, y_start, y_end = 1200, 1350, 150, 300  # 默认切片位置
        x_start, x_end, y_start, y_end = 300, 338, 37, 75  # 默认切片位置
        roi_top = (y_start, y_end, x_start, x_end, 'forehead')
        # 三块感兴趣区域：额头、左脸、右脸
        rois.append(roi_top)
        if cal_ptt == True:
            # lfx_start, lfx_end, lfy_start, lfy_end = 1935, 2085, 1275, 1425
            # rfx_start, rfx_end, rfy_start, rfy_end = 625, 775, 1275, 1425
            lfx_start, lfx_end, lfy_start, lfy_end = 483, 521, 318, 356
            rfx_start, rfx_end, rfy_start, rfy_end = 156, 194, 318, 356
            roi_left = (lfy_start, lfy_end, lfx_start, lfx_end, 'left cheek')
            roi_right = (rfy_start, rfy_end, rfx_start, rfx_end, 'right cheek')
            rois.append(roi_left)
            rois.append(roi_right)
    print("面部检测及ROI定位完成。")
    # print("序列一共 {:d} 张图片".format(LEN))
    print("--------------------------------------面部定位、分区、切片、存储完成--------------------------------------")

    '''
    3-2 图像处理只保留面部(提高信噪比)
    '''
    print("--------------------------------------面部图像预处理开始--------------------------------------")
    t_3 = []
    # 使用上面加载过的第一张图，使用INTER_AREA均值化替代矩阵遍历，大大加速
    # img = cv2.resize(img, (0, 0), fx=0.25, fy=0.25, interpolation=cv2.INTER_AREA)
    height = img.shape[0]
    width = img.shape[1]
    # dst = np.zeros((height, width, 1), np.uint8)
    dst2 = np.zeros((height, width, 1), np.uint8)
    '''
    使用hsv阈值法提取黑色所需范围，制作mask掩膜
    '''
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    # 我需要的颜色部分
    low_hsv = np.array([0, 0, 0])
    high_hsv = np.array([180, 255, 46])
    mask = cv2.inRange(hsv, lowerb=low_hsv, upperb=high_hsv)
    # cv2.namedWindow("mask", 0)
    # cv2.resizeWindow("mask", 600, 625)
    # cv2.imshow("mask", mask)
    '''
    设置卷积核,先腐蚀去掉小面积，再膨胀放大大面积，制作掩膜
    '''
    kernel = np.ones((10, 10), np.uint8)
    kernel2 = np.ones((16, 16), np.uint8)
    # kernel = np.ones((80, 80), np.uint8)
    # kernel2 = np.ones((85, 85), np.uint8)
    dst0 = cv2.erode(mask, kernel)
    dst = cv2.dilate(dst0, kernel2)

    # dst0 = cv2.dilate(mask, kernel)
    # dst = cv2.erode(dst0, kernel2)
    # cv2.namedWindow("dst", 0)
    # cv2.resizeWindow("dst", 600, 625)
    # cv2.imshow("dst", dst)
    for i in range(height):
        for j in range(width):
            dst2[i, j] = 255 - dst[i, j]
    for j in range(round(width / 2)):
        for i in range(height):
            if dst2[i, j] == 0:
                dst2[i, 0:j] = 0
    for j in range(round(width / 2), width):
        for i in range(height):
            if dst2[i, j] == 0:
                dst2[i, j:width] = 0
    for i in range(540, height):
        dst2[i, :] = 0
    # cv2.namedWindow("dst2", 0)
    # cv2.resizeWindow("dst2", 600, 625)
    # cv2.imshow("dst2", dst2)
    # cv2.waitKey(0)
    # '''
    # 上面的dst2是制作的人脸掩膜
    # '''
    for i in range(0, LEN):
        img = cv2.imread(os.path.join(path2, files_list[i]))
        t_3.append(img)  # t.shape是(102,2400,2500,3)

        # frame = cv2.resize(img, (0, 0), fx=0.25, fy=0.25, interpolation=cv2.INTER_AREA)
        # # 在这里增加图像的掩膜处理，把图像保存为只有脸部的新图像
        # frame1 = cv2.add(frame, np.zeros(np.shape(frame), dtype=np.uint8), mask=dst2)

        frame1 = cv2.add(img, np.zeros(np.shape(img), dtype=np.uint8), mask=dst2)
        img_crop = frame1[y_start:y_end, x_start:x_end]
        cv2.imwrite(slice_path + 'pic_' + str(i) + dataType2, img_crop)
        cv2.imwrite(face_path + 'pic_' + str(i) + dataType2, frame1)
        if cal_ptt == True:
            img_crop_lf = img[lfy_start:lfy_end, lfx_start: lfx_end]
            cv2.imwrite(lf_path + 'pic_' + str(i) + dataType2, img_crop_lf)
            img_crop_rf = img[rfy_start:rfy_end, rfx_start: rfx_end]
            cv2.imwrite(rf_path + 'pic_' + str(i) + dataType2, img_crop_rf)

    print("--------------------------------------面部图像预处理完成--------------------------------------")

    '''
    3-3 计算脉搏传递时间PTT
    '''
    if cal_ptt == True:
        fps = fps
        low = 0.5
        high = 5
        ptt(path2, path3, rois, fps, low, high, dataType2)  # 计算脉搏传递时间，并制图存储结果
        # ptt(face_path, path3, rois, fps, low, high, dataType2)  # 计算脉搏传递时间，并制图存储结果

    return path1, LEN, center_all, tri_list
```

```python
'''
run方法
'''
# 计算额头、左脸、右脸参数，默认值暂不修改（但无）
def run(img_path, cal_ptt = False):
    try:
        tri_list, new_cen = return_new_cen(img_path)
        # print("tri_list:", tri_list, "new_cen:", new_cen) # 得到的都是左边，还返回了一个txt文件记录了额头三角区
        '''plot triangle'''
        img2 = cv2.imread(img_path)
        img3 = np.zeros(img2.shape)
        img3 = img3.astype(np.uint8)  # 转换数据类型，img3用作掩膜
        for i in range(len(tri_list)):
            # tri_list[i]是个array
            cv2.line(img3, (tri_list[i][0][0], tri_list[i][0][1]), (tri_list[i][1][0], tri_list[i][1][1]), (255, 255, 255),
                     1)  # cv2.line(image, start_point, end_point, color, thickness) 每个列表的第一个点和第二个点连线
            cv2.line(img3, (tri_list[i][0][0], tri_list[i][0][1]), (tri_list[i][2][0], tri_list[i][2][1]), (255, 255, 255),
                     1)  # 每个列表的第一个点和第三个点连线
            cv2.line(img3, (tri_list[i][1][0], tri_list[i][1][1]), (tri_list[i][2][0], tri_list[i][2][1]), (255, 255, 255),
                     1)  # 每个列表的第二个点和第三个点连线

        masked = cv2.add(img2, img3)  # 将图片混叠
        cv2.imwrite("E:\\code_path\\path_5\\added_up.jpg", masked)
        with open("E:\\code_path\\path_5\\coordinate.txt", "w") as f:
            f.write("%d\n%d" % (int(new_cen[20][1]), int(new_cen[20][0])))  # 与python顺序一致，把眉心位置输出，写入txt文件存储

        if cal_ptt == True:
            return new_cen[20], new_cen[58], new_cen[59], new_cen, tri_list  # 如果计算左右脸ptt，则再返回左右脸中心坐标
        else:
            return new_cen[20]  # 额头,与画图顺序一致
    except :
        # 没检测到人脸的情况
        img2 = cv2.imread(img_path)
        img3 = cv2.imread("E:\\code_path\\path_5\\mask.jpg")
        img3 = cv2.resize(img3, (img2.shape[1], img2.shape[0]))
        masked = cv2.add(img2, img3)
        cv2.imwrite("E:\\code_path\\path_5\\added_up.jpg", masked)
        with open("E:\\code_path\\path_5\\coordinate.txt", "w") as f:
            f.write("275\n900")  # 佛山（275，900），额头位置默认值，与python顺序一致
        if cal_ptt == True:
            return 0, 0, 0
        else:
            return 0

```

```python
'''triangle set'''
def return_new_cen(img_path):
    points = return_list(img_path)  # 找到87个面部特征界标
    # print("points:", points)
    # print("type_points:", type(points))
    # print("shape_points:", len(points))
    #    tri_set = [[75,76,19],[79,74,25],[76,69,19],[80,79,24],[69,70,19],[71,80,23],
    #               [69,72,71],[71,21,22],[0,17,36],[45,16,26],
    #               [17,18,36],[26,25,45],[18,36,37],[44,45,25],[18,19,37],[24,25,44],
    #               [19,20,37],[23,24,44],[37,20,38],[23,44,43],[20,38,85],[86,43,23],
    #               [20,21,85],[22,23,86],[21,85,27],[27,22,86],
    #               [85,39,27],[27,86,42],[21,22,27],[39,27,28],[27,42,28],[39,83,28],
    #               [28,42,84],[83,28,29],[28,84,29],[0,1,36],[45,16,15],[1,41,83],
    #               [46,84,15],[36,41,1],[45,46,15],[41,40,83],[47,46,84],[1,2,41],
    #               [14,15,46],[2,81,41],[46,14,82],[41,83,81],[84,82,46],[83,29,81],
    #               [84,29,82],[2,3,81],[14,13,82],[81,29,31],[29,82,35],[31,29,30],
    #               [30,35,29],[3,4,81],[82,12,13],[4,48,81],[82,12,54],[31,49],
    #               [35,53],[32,50],[52,34],[33,51],[4,5,48],[54,11,12],[48,59,5],
    #               [55,54,11],[5,59,6],[55,10,11],[6,7,58],[56,9,10],[7,9,57],[75,74,71],
    #               [29,30,2],[29,30,14]]

    tri_set = [[77, 17, 0], [26, 78, 16],
               [77, 17, 75], [26, 78, 74], [17, 18, 75], [25, 26, 74], [18, 19, 75], [24, 25, 74], [76, 75, 19],
               [79, 74, 24], [76, 69, 19], [72, 79, 24], [69, 70, 19], [72, 80, 24], [19, 20, 70],
               [23, 24, 80], [20, 21, 70, ], [22, 23, 80], [70, 71, 21], [71, 80, 22],
               [21, 22, 71], [0, 17, 36], [45, 16, 26], [17, 18, 36], [26, 25, 45], [18, 36, 37],
               [44, 45, 25], [18, 19, 37], [24, 25, 44], [19, 20, 37], [23, 24, 44],
               [37, 20, 38], [23, 44, 43], [20, 38, 85], [86, 43, 23], [20, 21, 85],
               [22, 23, 86], [21, 85, 27], [27, 22, 86], [85, 39, 27], [27, 86, 42],
               [21, 22, 27], [39, 27, 28], [27, 42, 28], [39, 83, 28], [28, 42, 84],
               [83, 28, 29], [28, 84, 29], [0, 1, 36], [45, 16, 15], [1, 41, 83],
               [46, 84, 15], [36, 41, 1], [45, 46, 15], [41, 40, 83], [47, 46, 84],
               [1, 2, 41], [14, 15, 46], [2, 81, 41], [46, 14, 82], [41, 83, 81], [84, 82, 46],
               [83, 29, 81], [84, 29, 82], [2, 3, 81], [14, 13, 82], [81, 29, 31],
               [29, 82, 35], [31, 29, 30], [30, 35, 29], [3, 4, 81], [82, 12, 13],
               [4, 48, 81], [82, 12, 54], [81, 32, 49], [82, 34, 53], [32, 49, 51], [53, 51, 34],
               [32, 34, 51], [4, 5, 48], [54, 11, 12], [48, 59, 5], [55, 54, 11], [5, 59, 6],
               [55, 10, 11], [6, 7, 58], [56, 9, 10], [58, 56, 8], [29, 30, 2], [29, 30, 14],
               [59, 58, 6], [56, 55, 10], [7, 8, 58], [8, 9, 56], [40, 39, 83], [42, 47, 84], [48, 49, 81],
               [53, 54, 82]]  # [21, 22, 71]为额头三角形 第一个参数是points中的顺序，
    new_cen = []
    tri_list = []
    for j, p in enumerate(tri_set):
        tmp1 = 0
        tmp2 = 0
        tmp3 = []
        # print(j, p)
        for i in range(len(p)):
            # if j == 20:
            #     if i > 0:
            #         tmp1 = tmp1 + points[p[i]][0]  # 额头中心不做三点平均，以免太靠下
            #         tmp2 = tmp2 + points[p[i]][1]
            #     else:
            #         tmp1 = tmp1 + points[p[i]][0]
            #         tmp2 = tmp2 * 1.5
            #     # for k in range(0, 3, 1):
            #     #     if k > 0:
            #     #         tmp1 =i tmp1 + points[p[k]][0]  # 额头中心不做三点平均，以免太靠下
            #     #         tmp2 = tmp2 + points[p[k]][1]
            #     #     else:
            #     #         tmp1 = tmp1 + points[p[k]][0]
            #     #         tmp2 = tmp2 * 1.5
            # else:
            #     tmp1 = tmp1 + points[p[i]][0]   # points中的点横坐标之和
            #     tmp2 = tmp2 + points[p[i]][1]   # points中的点纵坐标之和
            tmp1 = tmp1 + points[p[i]][0]  # points中的点横坐标之和
            tmp2 = tmp2 + points[p[i]][1]   # points中的点纵坐标之和
            tmp3.append(points[p[i]])    # 根据tri_set内容把points中的点追加进去
        tri_list.append(np.array(tmp3, np.int))
        # print('各个三角区域列表：', tri_list)
        x_m = int(tmp1 // len(p))
        y_m = int(tmp2 // len(p))
        new_cen.append([x_m, y_m])
    print('各个三角区域的中心点列表：', new_cen)
    print('new_cen[58]（图左脸） = ', new_cen[58])
    print('new_cen[59]（图右脸） = ', new_cen[59])
    # tri_list放的是每个三角区域的三个点的坐标
    # new_cen放的是每个三角区域的中心点的坐标（用以做ROI的中心）
    return tri_list, new_cen

```

```python
# 在这里面使用人脸检测器---自定义形状预测器模型
def return_list(img_path):
    # 获取人脸检测器
    # 自定义形状预测器模型经过训练，可以在给定任何图像的情况下找到81个面部特征界标
    print("人脸检测···")
    predictor = dlib.shape_predictor("E:\\code_path\\path_5\\shape_predictor_81_face_landmarks.dat")  # 获取经过训练的形状预测器
    detector = dlib.get_frontal_face_detector()  # 功能：人脸检测画框 参数：无 返回值：默认的人脸检测器
    img = cv2.imread(img_path)  # Read in the image.
    points = []  # Create an array of points.

    # detect point
    Gray = False
    if Gray == True:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    dets = detector(img, 1)
    '''
    函数：detector(img, 1)  
    功能：对图像画人脸框
    参数：img_gray：输入的图片 后面那个参数代表将原始图像是否进行放大，1表示放大1倍再检查，提高小人脸的检测效果。
    返回值：人脸检测矩形框4点坐标。坐标为[(x1, y1) (x2, y2)]。
    可以通过函数的left, right, top, bottom方法分别获取对应的x1, x2, y1, y2值。
    （cv里的矩阵和C + +的那种一样，左上角是(0, 0)
    点，水平为x方向，竖直为y方向，类似笛卡尔系(区别是y轴正方向不同)，所以top的y坐标 < bottom的y坐标。matplotlib是相反的。）
    '''
    print("人脸位置定位：", dets)
    face_rec = dets[0]
    shape = predictor(img, face_rec)  # 使用经过训练的形状预测器，使用位置根据面部修正点（面部定位左上角）自动定位
    print("形状预测器使用: ", shape)
    # 建立分析点列表并增加创建新的分析点
    sp = shape.parts()  # 获得81个点的坐标
    for pt in sp:
        x, y = pt.x, pt.y
        points.append((int(x), int(y)))  # 将81个点坐标追加进points列表中
    # 下面增加6个点的坐标，一共87个面部特征界标
    px_81 = sp[31].x + (sp[31].x - sp[32].x)
    py_81 = sp[31].y + (sp[31].y - sp[32].y)
    px_82 = sp[35].x + (sp[35].x - sp[34].x)
    py_82 = sp[35].y + (sp[35].y - sp[34].y)
    line1 = [sp[16].x, sp[16].y, sp[0].x, sp[0].y]
    line2 = [sp[21].x, sp[21].y, px_81, py_81]
    line3 = [sp[15].x, sp[15].y, sp[1].x, sp[1].y]
    line4 = [sp[22].x, sp[22].y, px_82, py_82]
    pt_83 = cross_point(line2, line3)  # 两条线的交点
    pt_84 = cross_point(line3, line4)
    pt_85 = cross_point(line1, line2)
    pt_86 = cross_point(line1, line4)
    points.append((px_81, py_81))  # 81
    points.append((px_82, py_82))  # 82
    points.append(pt_83)
    points.append(pt_84)
    points.append(pt_85)
    points.append(pt_86)
    #    remove_list = [0,16,70,80,60,61,62,63,67,66,65,41,46,
    #                   77,17,78,26,31,32,34,35,42,39,
    #                   49,53,58,56,59,55,68,73,38,36,45,
    #                   43,85,86,76,79,51,50,52,21,19,22,24,7,9,64,
    #                   5,11,3,13,83,84,30]
    #    value_list = []
    #    for ind in remove_list:
    #        value_list.append(points[ind])
    #    for val in value_list:
    #        points.remove(val)
    # 返回points列表
    return points
```

```python
# 得到IPPG序列函数
def getIPPGSequence(t, roi=None):
    """
    given sequence and roi, return the iPPG sequence

    parameters
    ----------
    t: input tensor[#frames, height, width, channel]
    roi: [top, bottom, left, right]

    return
    ------
    iPPG sequence of roi

    """
    if roi == None:
        y = [np.mean(y) for y in t]
    else:
        y = [np.mean(y) for y in t[:, roi[0]:roi[1], roi[2]:roi[3], 1]]  # iPPG signal of roi over the video

    return y
```

