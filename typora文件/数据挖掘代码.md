```python
data_path = path_5+'slice'

    if cal_data == True:
        try:
            IPPG_6.cal_ippg(data_path, fps, dataType=".bmp")  # 参数计算
        except:
            pass
```

```python
from datetime import datetime
import time
import os

import numpy as np
from scipy.interpolate import UnivariateSpline
from scipy.signal import butter, filtfilt, welch, periodogram, resample_poly, resample
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.mlab import psd
import cv2 as cv
from scipy.signal import find_peaks
# import exceptions

def HRV_parameters(X_peaks,sample_rate,freq_method='welch',measures={}):
    '''Calculation of HRV time domain, frequency domain and nonlinear parameters

    :param rr_list: time interval between adjacent effective peaks, referred to as "RR"
    :param method: method used to extract the frequency spectrum. Available: 'fft' (Fourier Analysis),
                   'periodogram', and 'welch' (Welch's method). (Default = 'welch')
    :param measures: Set of storage parameters
    :return: HRV parameters
    '''
    rr_list = (np.diff(X_peaks) / sample_rate) * 1000.0 #unit：ms
    ##去除异常拍间间隔：[250,2000]ms → [30,240]bpm
    for i in range(len(rr_list)-1,-1,-1):
        if rr_list[i]>2000 or rr_list[i]<250:
            del rr_list[i]

    font = {'family': 'Times New Roman',

            'weight': 'normal',

            'size': 15, }
    #1. time domain parameters
    rr_diff = np.abs(np.diff(rr_list))  #The difference between adjacent RR
    rr_sqdiff = np.power(rr_diff, 2)  #The square of the difference between adjacent RR
    measures['HR'] = 60000 / np.mean(rr_list) #Heart Rate
    measures['IBI'] = np.mean(rr_list) #Inter beat Interval
    measures['sdnn'] = np.std(rr_list) #Standard deviation of RR intervals
    measures['sdsd'] = np.std(rr_diff)  #Standard deviation of successive differences between adjacent R-R intervals
    measures['rmssd'] = np.sqrt(np.mean(rr_sqdiff)) #Root mean square of successive differences between adjacent R-R intervals
    nn20 = rr_diff[np.where(rr_diff > 20.0)]
    nn50 = rr_diff[np.where(rr_diff > 50.0)]
    try:
        measures['pnn20'] = float(len(nn20)) / float(len(rr_diff))  #Proportion of differences between R-R intervals greater than 20ms
    except:
        measures['pnn20'] = np.nan
    try:
        measures['pnn50'] = float(len(nn50)) / float(len(rr_diff))  #Proportion of differences between R-R intervals greater than 50ms
    except:
        measures['pnn50'] = np.nan

    # 2. frequency domain parameters
    rr_x = []
    pointer = 0
    for x in rr_list:
        pointer += x
        rr_x.append(pointer)
    rr_x_new = np.linspace(rr_x[0], rr_x[-1], int(rr_x[-1]))
    interpolated_func = UnivariateSpline(rr_x, rr_list, k=3)

    if freq_method == 'fft':
        datalen = len(rr_x_new)
        frq = np.fft.fftfreq(datalen, d=((1 / 1000.0)))
        frq = frq[range(int(datalen / 2))]
        Y = np.fft.fft(interpolated_func(rr_x_new)) / datalen
        Y = Y[range(int(datalen / 2))]
        psd = np.power(Y, 2)
    elif freq_method == 'periodogram':
        frq, psd = periodogram(interpolated_func(rr_x_new), fs=1000.0)
    elif freq_method == 'welch':
        frq, psd = welch(interpolated_func(rr_x_new), fs=1000.0, nperseg=100000)
    else:
        print("specified method incorrect, use 'fft', 'periodogram' or 'welch'")
        raise SystemExit(0)

    measures['frq'] = frq
    measures['psd'] = psd
    # PSD图
    plt.figure()
    ax = plt.subplot(1, 1, 1)
    plt.plot(measures['frq'], measures['psd'])
    plt.xlim([0, 1])
    plt.ylabel("(ms^2)", font)
    plt.xlabel("Frequency (Hz)", font)
    plt.title("Power Spectrum Density", font)
    plt.tick_params(labelsize=15)  ##~~~设置刻度字体大小
    labels = ax.get_xticklabels() + ax.get_yticklabels()
    [label.set_fontname('Times New Roman') for label in labels]
    plt.tight_layout()

    ## 对PSD拟合，很坐标细化成0.01，方便用trapz求面积
    fun_new_psd = UnivariateSpline(frq, psd, k=1,s=1)
    new_freq=np.linspace(0,1,101)
    new_psd = fun_new_psd(new_freq)
    # 查看拟合效果图
    plt.figure()
    ax = plt.subplot(1, 1, 1)
    plt.plot(frq, psd, '.-',label ="Original")
    plt.plot(new_freq, new_psd,label = "Interpolation")
    plt.title("Power Spectrum Density fitting",font)
    plt.ylabel("(ms^2)", font)
    plt.xlabel("Frequency (Hz)", font)
    plt.xlim([0,1])
    plt.legend(loc=0,prop = font)
    plt.tick_params(labelsize=15)  ##~~~设置刻度字体大小
    labels = ax.get_xticklabels() + ax.get_yticklabels()
    [label.set_fontname('Times New Roman') for label in labels]
    plt.tight_layout()

    measures['lf'] = np.trapz(new_psd[4:15], new_freq[4:15])
    measures['hf'] = np.trapz(new_psd[15:40], new_freq[15:40])
    if measures['hf']==0.0:
        measures['lf/hf'] ="nan"
    else:
        measures['lf/hf']=measures['lf']/measures['hf']


    # 3. 非线性参数
    S1 = []
    S2 = []
    for i in range(len(rr_list) - 1):
        S1.append(rr_list[i + 1] - rr_list[i])
        S2.append(rr_list[i + 1] + rr_list[i])
    measures['SD1'] = np.std(S1) / np.sqrt(2)
    measures['SD2'] = np.std(S2) / np.sqrt(2)
    measures['SD1/SD2'] = measures['SD1'] / measures['SD2']

    plt.figure()
    ax = plt.subplot(1, 1, 1)
    plt.ylabel("RR(n+1)/ms", font)
    plt.xlabel("RR(n)/ms", font)
    for i in range(len(rr_list) - 2):
        plt.plot(rr_list[i], rr_list[i + 1], color='k',
                 markerfacecolor='black',
                 marker='o')
    plt.xlim([0, 1400])
    plt.ylim([0, 1400])
    plt.title("Nonlinear scatter plot", font)
    plt.tick_params(labelsize=15)
    labels = ax.get_xticklabels() + ax.get_yticklabels()
    [label.set_fontname('Times New Roman') for label in labels]
    plt.tight_layout()
    plt.show()

    return measures

def Peaks_Detection(Data, fps , measures={}):

    font = {'family': 'Times New Roman',

            'weight': 'normal',

            'size': 15, }

    X_Peaks, Peaks = find_peaks(Data, distance=fps // 2)
    Y_Peaks = []
    for i in range(0, len(X_Peaks)):
        Y_Peaks.append(Data[X_Peaks[i]])
    ###~~~~~去除异常的峰值
    reject_Peaks = []
    reject_xPeaks = []
    reject_yPeaks = []
    Y_mean = np.mean(Y_Peaks)
    for i, j in enumerate(Y_Peaks):
        if j > Y_mean * 2 or j < 0.3 * Y_mean:
            reject_Peaks.append(i)
            reject_xPeaks.append(X_Peaks[i])
            reject_yPeaks.append(Y_Peaks[i])
    X_Peaks = X_Peaks.tolist()
    for i in range(len(reject_Peaks) - 1, -1, -1):
        del X_Peaks[reject_Peaks[i]]
        del Y_Peaks[reject_Peaks[i]]

    plt.figure(figsize=(10,5))
    ax=plt.subplot(1,1,1)
    plt.plot(Data, color='navy',label='Pulse signal')
    plt.scatter(X_Peaks, Y_Peaks, color='lime', label='Effective peak point')
    plt.scatter(reject_xPeaks, reject_yPeaks, color='red', label='Rejected peaks')
    plt.title("Peak_Detection",font)
    plt.legend(loc=0,prop=font)
    plt.tick_params(labelsize=15)  ##~~~设置刻度字体大小
    labels = ax.get_xticklabels() + ax.get_yticklabels()
    [label.set_fontname('Times New Roman') for label in labels]
    plt.tight_layout()

    measures['X_Peaks'] = X_Peaks
    measures['Y_Peaks'] = Y_Peaks

    return measures


def butter_lowpass(cutoff, sample_rate, order=2):
    '''Defines standard Butterworth lowpass filter.
    '''
    nyq = 0.5 * sample_rate
    normal_cutoff = cutoff / nyq
    b, a = butter(order, normal_cutoff, btype='low', analog=False)
    return b, a

def butter_highpass(cutoff, sample_rate, order=2):
    '''Defines standard Butterworth lowpass filter.
    '''
    nyq = 0.5 * sample_rate
    normal_cutoff = cutoff / nyq
    b, a = butter(order, normal_cutoff, btype='high', analog=False)
    return b, a

def butter_bandpass(lowcut, highcut, fs, order=5):
    '''Defines standard Butterworth bandpass filter.
    '''
    nyq = 0.5 * fs
    low = lowcut / nyq
    high = highcut / nyq
    b, a = butter(order, [low, high], btype='band')
    return b, a

def filtersignal(Mean_Data,Time, cutoff, sample_rate, order, filtertype='lowpass',show=True):
    '''Applies the Butterworth lowpass filter

    Keyword arguments:
    data -- 1-dimensional numpy array or list containing the to be filtered data
    cutoff -- the cutoff frequency of the filter. Expects float for low and high types
              for bandpass filter expects list or array [low, high]
    sample_rate -- the sample rate of the data set
    order -- the filter order (default 2)
    '''
    data=Mean_Data
    for i in range(3):

        if filtertype == 'lowpass':
            b, a = butter_lowpass(cutoff, sample_rate, order=order)
        elif filtertype == 'highpass':
            b, a = butter_highpass(cutoff, sample_rate, order=order)
        elif filtertype == 'bandpass':
            b, a = butter_bandpass(cutoff[0], cutoff[1], sample_rate, order=order)
        data[:,i] = filtfilt(b, a, Mean_Data[:,i])

    plotData(data, Time, show=show, title="Filter_Data-"+filtertype)

    return data

def slidingMean(Orig_Data,Time, windowSize=30,show=True):
    Mean_Data = Orig_Data
    for i in range(Orig_Data.shape[1]):
        S = np.convolve(Orig_Data[:, i], np.ones((windowSize,)), mode='same')
        N = np.convolve(np.ones((Orig_Data[:, i].size,)), np.ones((windowSize,)), mode='same')
        Mean_Data[:, i] = (Orig_Data[:, i] - S / N)

    plotData(Mean_Data, Time, show=show, title="Data_MeanCentered")
    return Mean_Data

def plotData(Data, t, show, title="data"):
    font = {'family': 'Times New Roman',

            'weight': 'normal',

            'size': 15, }
    c, r = Data.shape
    colors = plt.cm.jet(np.linspace(0, 1, r))
    if r >= 6:
        r = 0
    if show:
        plt.figure(figsize = (10,10))
        plt.subplot(r + 1, 1, 1)

        for i in range(0, Data.shape[1]):
            plt.plot(t, Data[:, i], c=colors[:, i])
        plt.legend(['B','G','R'], loc=2)
        plt.title(title,font)

        for i in range(0,r):
            plt.subplot(r + 1, 1, i+2)
            plt.plot(t, Data[:, i], c=colors[:, i])
    plt.tight_layout()  # 自动调整子图参数，使之填充整个图像区域。

def SegData(DataAll=np.zeros([16912,100,100, 3]), t=np.zeros([100,1]), indX=([10, 30]), indY=([10, 30]),show=True):
    '''
    image segmentation data from the DataAll
    :return: Data, t
    '''

    font = {'family': 'Times New Roman',

            'weight': 'normal',

            'size': 15, }
    Data = DataAll[:, indX[0]:indX[1], indY[0]:indY[1], :]
    temp = np.mean(Data, axis=1)
    Data = np.mean(temp, axis=1) #ROI区域空间像素平均

    if show:

        #ROI_crop
        plt.figure(1)
        plt.imshow(DataAll[1, :, :, :])
        plt.title("segmentation: " + str(indX) + str(indY), font)
        plt.plot(range(indY[0], indY[1]), np.ones([indY[1]-indY[0], 1])*indX[0], '-', linewidth=5, color='firebrick')
        plt.plot(range(indY[0], indY[1]), np.ones([indY[1]-indY[0], 1])*indX[1], '-', linewidth=5, color='firebrick')
        plt.plot(np.ones([indX[1]-indX[0], 1])*indY[0], range(indX[0], indX[1]), '-', linewidth=5, color='firebrick')
        plt.plot(np.ones([indX[1] - indX[0], 1]) * indY[1], range(indX[0], indX[1]), '-', linewidth=5, color='firebrick')

        #ROI show
        plt.figure()
        plt.imshow(DataAll[1, indX[0]:indX[1], indY[0]:indY[1], :]/255)
        plt.title("ROI: "+ str(indX) + str(indY),font)
        #Orig_Signal show
        plotData(Data, t, show=show, title="Orig_Signal_BGR")

    return Data



def cal_ippg(path, fps, dataType='.bmp'):
    indX = ([0, 36])  # ROI [x1,x2]
    indY = ([0, 36])  # [y1,y2]

    ###~~~~~~~~图像序列获取~~~~~~~~~
    pathDir2 = os.listdir(path)
    LEN2 = 0
    for i, tmp in enumerate(pathDir2):
        if dataType in tmp:
            LEN2 += 1
            if LEN2 == 1:
                first_img2 = i
    pathDir2 = pathDir2[first_img2:first_img2 + LEN2]
    files_list2 = sorted(pathDir2, key=lambda x: int("".join(x.split(".")[0].split("_")[1])))
    ###~~~~~~原始信号提取~~~~~~~~~
    Orig_Signal = []
    for i in range(0, LEN2):
        img2 = cv.imread(os.path.join(path, files_list2[i]))
        Orig_Signal.append(img2)
    Orig_Signal = np.array(Orig_Signal)  # shape(16912,150,148,3)

    ###~~~~~~~~~~~ROI信号提取~~~~~~~~~~~~
    time = np.linspace(0, Orig_Signal.shape[0] / fps - 1 / fps, Orig_Signal.shape[0])
    Orig_Data = SegData(Orig_Signal, time, indY, indX, show=True)  ##Data:2D_array[16912,3],Time:1D

    ###~~~~~~~滑动平均+滤波~~~~~~~~~~~
    Mean_Data = slidingMean(Orig_Data, Time=time, windowSize=fps // 2, show=True)
    filter_Data = filtersignal(Mean_Data, Time=time, cutoff=[0.5, 5], sample_rate=fps, order=2, filtertype="bandpass",
                               show=True)

    ###~~~~~~~峰值检测-G通道~~~~~~~~~~~~
    measures = Peaks_Detection(Data=filter_Data[:, 1], fps=fps, measures={})

    ###~~~~~~~HRV calculate~~~~~~~
    HRV_parameters(measures['X_Peaks'], sample_rate=fps, freq_method='welch', measures=measures)

    ##所有的HRV参数值均在measures
    for m in measures.keys():
        print(m + ': ' + str(measures[m]))
```

```python
import pickle
from one_way_ANOVA import ptl_anovaR
import pandas as pd
import numpy as np
from sklearn import svm
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.metrics import accuracy_score
from sklearn import preprocessing

#%% md

## 装载

#%%

with open("E:\\Py Project\\ippg_new_20210317\\name_list,nor_data,cor_data,hyper_data.txt", 'rb') as f:
    ff = pickle.load(f)
variables, normal, coronary, hypertension = ff[0],ff[1], ff[2], ff[3]
"""iPPG data"""
iPPG_data = []#列表里放字典
ddd = []
for i in range(2,22):
    ddd.append(i)
    ippg = {'normal': normal[:len(hypertension[:,i]),i],# 个数相同,取normal的第0~50组数据,共51组
                'hypertension': hypertension[:,i]}
    iPPG_data.append(ippg)

#%%

normal_look = pd.DataFrame(normal[:,2:],columns=['bpm','IBI','SDNN','SDSD','RMSSD','pNN20','pNN50','LF','HF','LF/HF','SD1','SD2','SD1/SD2','breathingRate','Hb','Hc','Hd','T','Tab','Tbd'])
normal_look

#%%

hypertension_look = pd.DataFrame(hypertension[:,2:],columns=['bpm','IBI','SDNN','SDSD','RMSSD','pNN20','pNN50','LF','HF','LF/HF','SD1','SD2','SD1/SD2','breathingRate','Hb','Hc','Hd','T','Tab','Tbd'])
hypertension_look

#%%

iPPG_data  #整理数据的结果

#%%

normal.shape

#%%

np.shape(iPPG_data)

#%% md

## Anova

#%%

res_pd = pd.DataFrame(iPPG_data)
res_pd.to_csv('HRV Parameters.CSV')

#%%

"""放字典"""
from statsmodels.formula.api import ols
from statsmodels.stats.anova import anova_lm
res = {}
variable_array = []
"""ANOVA"""
for i in range(20):
    df = pd.DataFrame(iPPG_data[i])
    df_melt = df.melt()  #Series变形
    df_melt.columns = ['Category','Value']
    model = ols('Value~C(Category)',data=df_melt).fit()
    anova_table = anova_lm(model, typ = 2)
    F = anova_table.loc['C(Category)','F']
    p = anova_table.loc['C(Category)','PR(>F)']
    res[variables[i+2]] = [F,p]
res
#     F, p = ptl_anovaR(pd.DataFrame(iPPG_data[i]))
#     res[variables[i+2]] = [F,p]

#%%

res_pd2 = pd.DataFrame(res)
res_pd2  #这是方差分析的结果表格

#%% md

## 箱型图的绘制

#%%

# (1.bpm)
# from statsmodels.formula.api import ols
# from statsmodels.stats.anova import anova_lm
# iPPG_data[1]
df = pd.DataFrame(iPPG_data[0])
df.head()
df.boxplot(grid = True)
#绘制箱型图
import matplotlib.pyplot as plt
plt.show()

# F,p = ptl_anovaR(pd.DataFrame(iPPG_data[0]))
df_melt = df.melt()  #Series变形
# df_melt.head()
df_melt 
df_melt.columns = ['Category','Value']
df_melt.head()  #预览前几行
# # 使用seaborn模块绘制箱线图(bpm心率)
# import seaborn as sns
# sns.boxplot(x='Category',y='Value',data = df_melt)

#%%

# (2.ibi)
# from statsmodels.formula.api import ols
# from statsmodels.stats.anova import anova_lm
# iPPG_data[1]
df = pd.DataFrame(iPPG_data[1])
df.head()
df.boxplot(grid = True)
#绘制箱型图
import matplotlib.pyplot as plt
plt.show()

# F,p = ptl_anovaR(pd.DataFrame(iPPG_data[1]))
df_melt = df.melt()  #Series变形
# df_melt.head()
df_melt 
df_melt.columns = ['Category','Value']
df_melt.head()  #预览前几行
# # 使用seaborn模块绘制箱线图(ibi相邻两次脉搏的时间间隔)
# import seaborn as sns
# sns.boxplot(x='Category',y='Value',data = df_melt)

#%%

# (3.lf/hf)
# from statsmodels.formula.api import ols
# from statsmodels.stats.anova import anova_lm
# iPPG_data[1]
df = pd.DataFrame(iPPG_data[9])
df.head()
df.boxplot(grid = True)
#绘制箱型图
import matplotlib.pyplot as plt
plt.show()

# F,p = ptl_anovaR(pd.DataFrame(iPPG_data[9]))
df_melt = df.melt()  #Series变形
# df_melt.head()
df_melt 
df_melt.columns = ['Category','Value']
df_melt.head()  #预览前几行
# # 使用seaborn模块绘制箱线图(lf/hf低高频比，反应自主神经系统的平衡状态，基本上代表交感神经张力的高低)
# import seaborn as sns
# sns.boxplot(x='Category',y='Value',data = df_melt)

#%%

# (4.SD2)
# from statsmodels.formula.api import ols
# from statsmodels.stats.anova import anova_lm
# iPPG_data[1]
df = pd.DataFrame(iPPG_data[11])
df.head()
df.boxplot(grid = True)
#绘制箱型图
import matplotlib.pyplot as plt
plt.show()

# F,p = ptl_anovaR(pd.DataFrame(iPPG_data[11]))
df_melt = df.melt()  #Series变形
# df_melt.head()
df_melt 
df_melt.columns = ['Category','Value']
df_melt.head()  #预览前几行
# # 使用seaborn模块绘制箱线图(SD2非线性评估下椭圆长轴标准差，长轴主要反映交感神经的状态)
# import seaborn as sns
# sns.boxplot(x='Category',y='Value',data = df_melt)

#%%

# (5.Tab)
# from statsmodels.formula.api import ols
# from statsmodels.stats.anova import anova_lm
# iPPG_data[1]
df = pd.DataFrame(iPPG_data[18])
df.head()
df.boxplot(grid = True)
#绘制箱型图
import matplotlib.pyplot as plt
plt.show()

# F,p = ptl_anovaR(pd.DataFrame(iPPG_data[18]))
df_melt = df.melt()  #Series变形
# df_melt.head()
df_melt 
df_melt.columns = ['Category','Value']
df_melt.head()  #预览前几行
# # 使用seaborn模块绘制箱线图(Tab从波谷到主波的时间)
# import seaborn as sns
# sns.boxplot(x='Category',y='Value',data = df_melt)

#%%

# #test
# from statsmodels.formula.api import ols
# from statsmodels.stats.anova import anova_lm
# model = ols('Value~C(Category)',data=df_melt).fit()
# anova_table = anova_lm(model, typ = 2)
# anova_table.loc['C(Category)','F']
# anova_table.loc['C(Category)','PR(>F)']
# # print(anova_table)

#%%

normal
hypertension

#%% md

## SVM分类器

#%%

# 使用方差分析出的区别明显的5个参数作为特征
import copy
from sklearn.model_selection import validation_curve
import matplotlib.pyplot as plt
normal1 = np.zeros([51,5])
hypertension1 = np.zeros([51,5])
normal1[:,0] = copy.deepcopy(normal[0:51,2])
normal1[:,1] = copy.deepcopy(normal[0:51,3])
normal1[:,2] = copy.deepcopy(normal[0:51,11])
normal1[:,3] = copy.deepcopy(normal[0:51,13])
normal1[:,4] = copy.deepcopy(normal[0:51,20])
hypertension1[:,0] = copy.deepcopy(hypertension[:,2])
hypertension1[:,1] = copy.deepcopy(hypertension[:,3])
hypertension1[:,2] = copy.deepcopy(hypertension[:,11])
hypertension1[:,3] = copy.deepcopy(hypertension[:,13])
hypertension1[:,4] = copy.deepcopy(hypertension[:,20])
# len(normal1)
# np.shape(normal1)
# np.shape(hypertension1)
# # type(normal1)
# # normal1
# # hypertension1
#两个参数分别是一个51*5的ndarray

#%%

X = np.concatenate((normal1,hypertension1),axis=0)  # 将normal1和hypertension1整合，X是一个102*5的ndarray
min_max_scaler = preprocessing.MinMaxScaler() # 属性缩放到一个指定的最大和最小值（通常是1-0）之间
X = min_max_scaler.fit_transform(X)
Y = np.zeros(X.shape[0])
Y = np.array(Y,dtype=int) #预定义102个0
Y[:normal1.shape[0]] = 1  #打标签，前51个为normal，标签是1，后51个为hypertension，标签是0
X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.1,random_state=4)   #按9：1划分训练集和测试集 个数分别：91、11
rbf_svc = svm.SVC(kernel='rbf').fit(X_train,  y_train)  # ‘rbf’：径像核函数/高斯核,
# fit() 方法：用于训练SVM，具体参数已经在定义SVC对象的时候给出了，这时候只需要给出数据集X和X对应的标签y即可。
# param_range = np.logspace(-6, -1,5) 
param_range = np.linspace(0, 100,1000) 
train_scores, test_scores = validation_curve(
    rbf_svc, X, Y, param_name="gamma", param_range=param_range,
    scoring="accuracy")  # 验证曲线与超参数，使用validation_curve找出模型对参数的影响,param_name是要评估的参数,param_range是选用的参数

#%%

train_scores_mean = np.mean(train_scores, axis=1)
train_scores_std = np.std(train_scores, axis=1)
test_scores_mean = np.mean(test_scores, axis=1)
test_scores_std = np.std(test_scores, axis=1)
plt.title("Validation Curve with SVM")
plt.xlabel(r"$\gamma$")
plt.ylabel("Score")
plt.ylim(0.0, 1.1)
lw = 2
plt.semilogx(param_range, train_scores_mean, label="Training score",
             color="darkorange", lw=lw)
plt.fill_between(param_range, train_scores_mean - train_scores_std,
                 train_scores_mean + train_scores_std, alpha=0.2,
                 color="darkorange", lw=lw)
plt.semilogx(param_range, test_scores_mean, label="Cross-validation score",
             color="navy", lw=lw)
plt.fill_between(param_range, test_scores_mean - test_scores_std,
                 test_scores_mean + test_scores_std, alpha=0.2,
                 color="navy", lw=lw)
plt.legend(loc="best")
plt.show()

#%% md

## gamma排序后坐标

#%%

sorted_nums = sorted(enumerate(test_scores_mean), key=lambda x: x[1],reverse=True)
idx = [i[0] for i in sorted_nums]
nums = [i[1] for i in sorted_nums]
print([gamma/10 for gamma in idx[:100]])
# len(idx[0:100])
sorted_nums #选择gamma 为2.2

#%% md

## C

#%%

rbf_svc = svm.SVC(kernel='rbf',gamma=2.2).fit(X_train,  y_train)
param_range = np.linspace(0.001, 10,1000) 
train_scores, test_scores = validation_curve(
    rbf_svc, X, Y, param_name="C", param_range=param_range,
    scoring="accuracy")
train_scores_mean = np.mean(train_scores, axis=1)
train_scores_std = np.std(train_scores, axis=1)
test_scores_mean = np.mean(test_scores, axis=1)
test_scores_std = np.std(test_scores, axis=1)
plt.title("Validation Curve with SVM")
plt.xlabel("C")
plt.ylabel("Score")
plt.ylim(0.0, 1.1)
lw = 2
plt.semilogx(param_range, train_scores_mean, label="Training score",
             color="darkorange", lw=lw)
plt.fill_between(param_range, train_scores_mean - train_scores_std,
                 train_scores_mean + train_scores_std, alpha=0.2,
                 color="darkorange", lw=lw)
plt.semilogx(param_range, test_scores_mean, label="Cross-validation score",
             color="navy", lw=lw)
plt.fill_between(param_range, test_scores_mean - test_scores_std,
                 test_scores_mean + test_scores_std, alpha=0.2,
                 color="navy", lw=lw)
plt.legend(loc="best")
plt.show()

#%% md

### C排序后坐标

#%%

sorted_nums = sorted(enumerate(test_scores_mean), key=lambda x: x[1],reverse=True)
idx = [i[0] for i in sorted_nums]
nums = [i[1] for i in sorted_nums]
print([c/100+0.001 for c in idx[:100]])
sorted_nums # 选择c为0.971

#%%

X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.1,random_state=5)
rbf_svc = svm.SVC(kernel='rbf',gamma=2.2,C=0.971).fit(X_train,  y_train)
y_pre = rbf_svc.predict(X_test) 
#predict() 方法: 基于以上的训练，对预测样本T进行类别预测，因此只需要接收一个测试集T，该函数返回一个数组表示个测试样本的类别。
score = accuracy_score(y_pre,y_test)
print(score)
print(y_pre)
print(y_test)

#%% md

### 去掉最不明显的一个特征SD2

#%%

#去掉第13列
normal1 = np.zeros([51,5])
hypertension1 = np.zeros([51,5])
normal1[:,0] = copy.deepcopy(normal[0:51,2])
normal1[:,1] = copy.deepcopy(normal[0:51,3])
normal1[:,2] = copy.deepcopy(normal[0:51,11])
normal1[:,3] = copy.deepcopy(normal[0:51,20])
hypertension1[:,0] = copy.deepcopy(hypertension[:,2])
hypertension1[:,1] = copy.deepcopy(hypertension[:,3])
hypertension1[:,2] = copy.deepcopy(hypertension[:,11])
hypertension1[:,3] = copy.deepcopy(hypertension[:,20])
X = np.concatenate((normal1,hypertension1),axis=0)
min_max_scaler = preprocessing.MinMaxScaler()
X = min_max_scaler.fit_transform(X)
Y = np.zeros(X.shape[0])
Y = np.array(Y,dtype=int)
Y[:normal1.shape[0]] = 1
X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.1,random_state=5)
rbf_svc = svm.SVC(kernel='rbf',gamma=2.2,C = 0.971).fit(X_train,  y_train)
y_pre = rbf_svc.predict(X_test)
score = accuracy_score(y_pre,y_test)
print(score)
```